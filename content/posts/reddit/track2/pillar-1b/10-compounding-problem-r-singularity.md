---
title: "Most AI products are equally useful on day 1 and day 100. That's a weird property that nobody talks about."
track: 2
target: r/singularity
pillar: 1b
status: ready
---

Something struck me recently about how AI products work compared to basically every other category of valuable software.

Your CRM gets more useful as you add contacts and deals. Your project management tool becomes essential as your team builds workflows around it. Your notes app becomes indispensable after years of accumulated knowledge. The value compounds with use.

AI products? ChatGPT on day 100 is roughly the same as ChatGPT on day 1. Claude with Projects on month 3 performs about the same as month 1. Your hundredth conversation is qualitatively similar to your first. The memory feature stores a few facts, but the fundamental capability doesn't deepen with continued use.

This is genuinely strange for a product category that's supposed to be intelligent.

**Why it matters:** If a product doesn't get better with use, several things follow:

1. **Switching costs are near zero.** If a better model ships tomorrow, there's nothing keeping you on the current one. No accumulated value to lose.
2. **Retention is driven by habit, not deepening value.** The product isn't becoming more essential over time — you just haven't found something better yet.
3. **Competition collapses to features and price.** Without compounding value, products compete on the latest model benchmark and the cheapest subscription. That's a race to the bottom.

**What compounding would actually look like in AI:**

* The system continuously syncs from your work platforms (Slack, email, docs, calendar) and builds understanding over time
* Every interaction teaches it something — when you edit a draft, it learns the difference between what it produced and what you wanted
* The 30th version of a recurring deliverable draws on 30 weeks of accumulated understanding
* You can actually measure the improvement: edit distance between the AI's drafts and your final versions decreases over time

The tricky part is the cold start. A compounding AI product looks identical to a non-compounding one on day 1. The magic only becomes visible after weeks of use. That's a tough sell in a market that evaluates tools based on first impressions.

But once the compounding kicks in, the dynamics completely change. The user has invested time building the system's understanding. That understanding is irreplaceable — a competitor can match your features, but they can't replicate months of accumulated context for a specific user. You get genuine switching costs based on accumulated value, not lock-in.

I've been building a product (yarnnn) around this thesis — that AI products need to compound with use to create real value. The Thinking Partner syncs from Slack, Gmail, Notion, and Calendar, accumulates context over time, and measurably improves its output as the context deepens. The fifth version of a client update needs fewer edits than the first.

Whether this specific approach works remains to be seen. But the underlying dynamic seems clear: the AI products that figure out genuine compounding will behave very differently in the market than the ones that are equally capable on day 1 and day 1000.

Anyone else think about this? The strange lack of compounding in current AI tools?
